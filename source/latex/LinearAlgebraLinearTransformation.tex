\documentclass[preview]{standalone}

\usepackage{amsmath,stackengine}
\usepackage{amssymb}
\usepackage{stellar}
\usepackage{definitions}

\hypersetup{
    colorlinks=true,
    linkcolor=black,
    urlcolor=blue,
    pdftitle={Stellar},
    pdfpagemode=FullScreen,
}

\stackMath{}

\begin{document}

\title{Stellar}
\id{linearalgebra-linear-transformation}
\genpage

\section{Linear Transformation}

\subsection{Definition}

\begin{snippetdefinition}{linear-transformation-definition}{Linear Transformation}
    Let \(\mathcal{V}\) and \(\mathcal{W}\) be vector spaces over a field \((K, +, \cdot)\).
    A \function \(f \colon \mathcal{V} \to \mathcal{W}\) is a
    \textit{linear transformation} if for any two vector \(\vec{u}, \vec{v} \in \mathcal{V}\)
    and any scalar \(c\in K\)
    \begin{enumerate}
        \item \(f(\vec{u} + \vec{v}) = f(\vec{u}) + f(\vec{v})\);
        \item \(f(c\cdot\vec{u}) = c\cdot f(\vec{u})\).
    \end{enumerate}
\end{snippetdefinition}

\subsection{The basis}

%\plain{Multiplying a vector by a matrix produces another vector. This is a linear transformation.
%The matrix contains the information about the transformation.}

\begin{snippettheorem}{linear-transformation-on-basis}{Linear transformation on basis}
    Given a basis for a vector space

    \[
        \mathcal{B}=\{\vec{b}_1, \vec{b}_2, \ldots, \vec{b}_n\}
    \]
    and a linear transformation \(T\), it suffices
    to know the value of \(T\mathcal{B}=\{T\vec{b}_1, T\vec{b}_2, \ldots, T\vec{b}_n\}\)
    to determine \(T\) applied to any vector on the vector space.
    Any transformation \(T\) is completely described by \(\mathcal{B}\)
    and \(T\mathcal{B}\).
\end{snippettheorem}

\begin{snippetproof}{linear-transformation-on-basis-proof}{linear-transformation-on-basis}{Linear transformation on basis}
    Given a basis for a vector space

    \[
        \mathcal{B}=\{\vec{b}_1, \vec{b}_2, \ldots, \vec{b}_n\}
    \]
    
    we can expand a vector \(\vec{a}\) along this basis
    
    \[
        \vec{a} = \sum_{k=1}^{n} \alpha_k \mathcal{B}_k
    \]
    
    We then apply a transformation \(T\) to the vector \(\vec{a}\) and use the properties of
    linear transformations
    
    \[
        T\vec{a}
        = T\sum_{k=1}^{n} \alpha_k \mathcal{B}_k
        = \sum_{k=1}^{n} \alpha_k T\mathcal{B}_k
    \]
\end{snippetproof}

\begin{snippet}{matrix-values-expl}
    Each column of a matrix is indeed the result of applying its transformation
    to the corresponding vector in the basis.
    Intuitively, this is given by the fact that we only need to know where the vectors of the basis
    end up after the transformation in order to represent the whole information.
\end{snippet}

\section{Determinants}

\begin{snippetdefinition}{determinant-definition}{Determinant}
    The \textit{determinant} of a square \snippetref[matrix-definition][matrix] \(M\),
    denoted \(\origdet(M)\),
    is a scalar which represents the factor by which the area of any shape (or volume and so on) changes
    after the linear transformation representes by the matrix is applied.
    If the transformation inverts the orientation of the space, the determinant is negative.
\end{snippetdefinition}

\begin{snippetdefinition}{matrix-minor-definition}{Matrix minor}
    Let \(M\) be a square matrix.
    The \textit{minor} of the entry in the \(i\)th row and \(j\)th column
    is the determinant of the submatrix formed by deleting the \(i\)th row and \(j\)th column.
    \[
        \text{minor of }b=
        \stackinset{c}{}{c}{1\baselineskip}{\rule{4.25\baselineskip}{0.5pt}}{
        \stackinset{c}{0\baselineskip}{c}{}{\rule{0.5pt}{3.5\baselineskip}}{
        \begin{vmatrix}
            a & b & c \\
            d & e & f \\
            g & h & i
        \end{vmatrix}}}
        =
        \begin{vmatrix}
            d & f \\
            g & i
        \end{vmatrix}
    \]
\end{snippetdefinition}

\begin{snippettheorem}{laplace-expansion-theorem}{Laplace expansion}
    The Laplace expansion is a formula that allows us to express the determinant of
    a matrix as a linear combination of the minors.
    \[
        \det(A)=\sum_{j=1}^{n}{(-1)}^{i+j}A_{ij}\det(\text{minor of }A_{ij})
    \]

    where \(i\) is any row.

    Instead of expanding the series along a row we could expand it along any column,
    the result is always the same.
\end{snippettheorem}

\begin{snippetexample}{laplace-expansion-2x2-example}{Determinant of \(2\times2\) matrix}
    Given a \(2 \times 2\) matrix \(A\)
    \[
        A=
        \begin{bmatrix}
            a & b \\
            c & d
        \end{bmatrix}
    \]
    its determinant is given by
    \[
        \det(A)=
        \begin{vmatrix}
            a & b \\
            c & d
        \end{vmatrix}
        \equiv ad-bc
    \]
    \phantom{}
\end{snippetexample}

\begin{snippetexample}{laplace-expansion-3x3-example}{Determinant of \(3\times3\) matrix}
    Given a \(3 \times 3\) matrix \(A\)
    \[
        A=
        \begin{bmatrix}
            a & b & c \\
            d & e & f \\
            g & h & i
        \end{bmatrix}
    \]
    its determinant is given by
    \[
        \det(A)=
        \begin{vmatrix}
            a & b & c \\
            d & e & f \\
            g & h & i
        \end{vmatrix}
        =
        a \begin{vmatrix}
            e & f \\
            h & i
        \end{vmatrix}
        -b \begin{vmatrix}
            d & f \\
            g & i
        \end{vmatrix}
        +c \begin{vmatrix}
            d & e \\
            g & h
        \end{vmatrix}
    \]
    \phantom{}
\end{snippetexample}

\begin{snippetproposition}{determinant-properties}{Properties of the determinant}
    Let \(A\) and \(B\) be two square matrices of the same size.
    The determinant has some properties, for instance

    \begin{align*}
        \det(A^\transpose)&=\det(A) \\
        \det(AB)&=\det(A)\det(B)
    \end{align*}
\end{snippetproposition}

\section{Change of basis}

\begin{snippettheorem}{change-of-basis-theorem}{Change of basis}
    Given a basis \(\mathcal{B}_1\) and \(\mathcal{B}_2\),
    there exists a matrix \(M\) such that \(M\vec{v}\) translates
    the vector from \(\mathcal{B}_1\) to \(\mathcal{B}_2\).
    
    The matrix \(M\) is formed by the columns of \(\mathcal{B}_1\) but written in
    \(\mathcal{B}_2\).
    
    The operation \(M^{-1}\vec{v}\) translates
    the vector from \(\mathcal{B}_2\) to \(\mathcal{B}_1\).
\end{snippettheorem}

\begin{snippetproposition}{change-of-basis-linear-transformation}{Change of basis of a linear transformation}
    If \(T_1\) is a transformation in \(\mathcal{B}_1\), we can find another
    transformation \(T_2\) that is similar to \(T_1\) but works for the basis \(\mathcal{B}_2\).
    
    Instead of computng \(T_1\vec{v}\), we first multiply \(\vec{v}\) by the
    change of basis matrix \(M\), then apply \(T_1\) and finally apply the inverse change of basis matrix \(M^{-1}\).
    \[
        T_2 = M^{-1}T_1M
    \]
\end{snippetproposition}

\end{document}