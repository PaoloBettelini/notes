\documentclass[preview]{standalone}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{parskip}
\usepackage{stellar}
\usepackage{bettelini}

\hypersetup{
    colorlinks=true,
    linkcolor=black,
    urlcolor=blue,
    pdftitle={Assets},
    pdfpagemode=FullScreen,
}

\begin{document}

\title{Linear Algebra Assets}

\begin{snippet}{linearalgebra-vector-definition}
\sdefinition{Vector}{
    A vector is a geometric object that has a direction and a magnitude. \\
Vectors don't have an origin point and they can be represented in any position on the space.

A vector can be expressed with its components

\[
    \vec{a} =
    \begin{pmatrix}
        x \\
        y \\
        z
    \end{pmatrix}
\]

For an n-dimensional vector

\[
    \vec{a} =
    \begin{pmatrix}
        \vec{a}_1 \\
        \vec{a}_2 \\
        \vdots \\
        \vec{a}_n
    \end{pmatrix},
    \quad \vec{a} \in \mathbb{R}^n
\]
}
\end{snippet}

\begin{snippet}{linearalgebra-linear-combination-definition}
\sdefinition{Linear Combination}{
    A linear combination is a sum of two or more vectors, each with a coefficient.

\[
    \vec{c} = a \cdot\vec{a} + b\cdot\vec{b},
    \quad a,b\in \mathbb{R}
\]
}
\end{snippet}

\begin{snippet}{linearalgebra-span-definition}
\sdefinition{Span}{
The \textit{span} of a set of vectors, is the set of every possible linear combination.
}
\end{snippet}

\begin{snippet}{linearalgebra-matrix-definition}
\sdefinition{Matrix}{
    A matrix is a rectangular array of elements.
Each matrix has a particular size expressed as \(n \times m\).
A generic matrix looks like the following

\[
A = \begin{bmatrix} 
        a_{1,1} & a_{1,2} & \cdots & a_{1,m} \\
        a_{2,1} & a_{2,2} & \cdots & a_{2,m} \\
        \vdots  & \vdots  & \ddots & \vdots  \\
        a_{n,1} & a_{n,2} & \cdots & a_{n,m} 
    \end{bmatrix}
\]
}
\end{snippet}

\begin{snippet}{linearalgebra-elementary-row-operations}
\sdefinition{Elementary row operations}{
    \begin{itemize}
        \item \textbf{Elementary row switching}:
        To switch two rows of a matrix.
        \item \textbf{Elementary row multiplication}:
        To multiply each element of a row by
        a scalar \(k \neq 0\).
        \item \textbf{Elementary row addition}:
        To add a multiple of every element of a row
        to each respective element of a another row.
    \end{itemize}
}
\end{snippet}

\begin{snippet}{linearalgebra-lin-sys-sol-amount}
\sproposition{Solutions of a system of linear equations}{
    A system of linear equations can have \(0\), \(1\)
    or an infinite amount of solutions.
}
\end{snippet}

\begin{snippet}{linearalgebra-matrix-linear-system-1-sol-example-1}
\sexample{Matrix linear system 1 solution}{
    \[
        \begin{bmatrix}
            1 & 1 & 1 & 2 \\
            3 & 1 & -2 & -2 \\
            2 & 4 & 1 & 0
        \end{bmatrix}
        \rightarrow
        \begin{bmatrix}
            1 & 0 & 0 & 1 \\
            0 & 1 & 0 & -1 \\
            0 & 0 & 1 & 2
        \end{bmatrix}
    \]
}
\end{snippet}

\begin{snippet}{linearalgebra-matrix-linear-system-inf-sol-example-1}
\sexample{Matrix linear system infinite solutions}{
    \[
        \begin{bmatrix}
            2 & -1 & 1 & 3 & 2 \\
            2 & -1 & 1 & 2 & 4 \\
            4 & -3 & 3 & 8 & 8
        \end{bmatrix}
        \rightarrow
        \begin{bmatrix}
            1 & 0 & 0 & -1 & 2 \\
            0 & 1 & -1 & -4 & 0 \\
            0 & 0 & 0 & 0 & 0
        \end{bmatrix}
    \]
}
\end{snippet}

\begin{snippet}{linearalgebra-matrix-linear-system-0-sol-example-1}
\sexample{Matrix linear system 0 solutions}{
    \[
        \begin{bmatrix}
            1 & 1 & 1 & 1 & 4 \\
            2 & 3 & -2 & -3 & 1 \\
            1 & 0 & 5 & 6 & 1
        \end{bmatrix}
        \rightarrow
        \begin{bmatrix}
            1 & 0 & -5 & -6 & -11 \\
            0 & 1 & -4 & -9 & -7 \\
            0 & 0 & 0 & 0 & 1
        \end{bmatrix}
    \]
}
\end{snippet}

\begin{snippet}{linearalgebra-zero-matrix-definition}
\sdefinition{Zero matrix}{
    The zero matrix, denoted \(0\) or \(0_{m,n}\)
    is defined as the matrix of size \((m \times n)\)
    where every element is \(0\).
}
\end{snippet}

\begin{snippet}{linearalgebra-matrix-addition-definition}
\sdefinition{Matrix addition}{
    Two matrices \(A\) and \(B\) of the same size
    with elements \(a_{i,j}\) and \(b_{i,j}\) respectively
    can be added. The resulting matrix \(A+B=C\)
    has elements \(c_{i,j} = a_{i,j} + b_{i,j}\).
}
\end{snippet}

\begin{snippet}{linearalgebra-matrix-scalar-multiplication-definition}
\sdefinition{Matrix scalar multiplication}{
    A matrix \(A\) with elements \(a_{i,j}\)
    can be multiplied by a scalar \(k\).
    The resulting matrix \(kA=B\) has elements
    \(b_{i,j} = k \cdot a_{i,j}\).
}
\end{snippet}

\begin{snippet}{linearalgebra-matrix-multiplication-definition}
\sdefinition{Matrix multiplication}{
    Two matrices \(A\) of size \((m \times n)\) and
    \(B\) of size \((p \times q)\)
    with elements \(a_{i,j}\) and \(b_{i,j}\) respectively
    can be multiplied if \(n=p\).
    The resulting matrix \(AB=C\) has elements
    \[
        c_{i,j} = \sum_{k=1}^n
        a_{i,k}b_{k,j}
    \]
    with \(1 \leq i \leq m\)
    and \(1 \leq j \leq q\).
}
\end{snippet}

\begin{snippet}{linearalgebra-kronecker-delta-definition}
\sdefinition{Kronecker delta}{
    The \textit{Kronecker delta} is a function of two variables
    defined as follows:
    \[
        \delta_{i,j} = \begin{cases}
            0 & i \neq j \\
            1 & i = j
        \end{cases}
    \]
}
\end{snippet}

\begin{snippet}{linearalgebra-identity-matrix-definition}
\sdefinition{Identity matrix}{
    The \textit{Identity matrix}, denoted \(I_n\),
    is a square matrix of side \(n\)
    with entries \(\delta_{i,j}\).
}
\end{snippet}

\begin{snippet}{linearalgebra-kronecker-delta-sifting-property}
\sproposition{Kronecker delta sifting property}{
    Let \(x_1, x_2, \cdots, x_n \in \mathbb{R}\)
    and \(1 \leq k \leq n\).
    \[
        \sum_{i=1}^n \delta_{i,k}x_i = x_k
    \]
}
\end{snippet}

\begin{snippet}{linearalgebra-matrix-premultiplication}
\sdefinition{Matrix premultiplication}{
    A matrix \(M\) can be \textit{premultiplied}
    by another matrix \(A\), resuling in \(AM\).
}
\end{snippet}

\begin{snippet}{linearalgebra-matrix-postmultiplication}
\sdefinition{Matrix postmultiplication}{
    A matrix \(M\) can be \textit{postmultiplied}
    by another matrix \(A\), resulting in \(MA\).
}
\end{snippet}

\begin{snippet}{linearalgebra-exponentiation-definition}
\sdefinition{Matrix exponentiation}{
    Given a square matrix \(M\), the power of a matrix
    is defin as
    \[
        M^k = \underbrace{M\cdot M \cdot M \cdots M}_{k \text{ times}}
    \]
}
\end{snippet}

\begin{snippet}{linearalgebra-polynomial-of-a-matrix-definition}
\sdefinition{Polynomial of a matrix}{
    Given a polynomial \(p(x)=\sum_{n=0}^k a_nx^n\)
    and a square matrix \(M\) we defined
    \[
        p(M) = \sum_{n=0}^k a_nM^n
    \]
}
\end{snippet}

\begin{snippet}{linearalgebra-matrix-exponentiation-definition}
\sdefinition{Matrix Exponentiation}{
    TODO
}
\end{snippet}

\begin{snippet}{linearalgebra-matrix-exponentiation-example-1}
\sexample{Matrix exponentiation example 1}{
    \begin{align*}
        & {\begin{bmatrix}
            \cos\alpha & \sin\alpha \\
            \sin\alpha & -\cos\alpha
        \end{bmatrix}}^2
        = \begin{bmatrix}
            \cos^2\alpha + \sin^2\alpha & \cos\alpha\sin\alpha - \sin\alpha\cos\alpha \\
            \cos\alpha\sin\alpha - \sin\alpha\cos\alpha & \cos^2\alpha + \sin^2\alpha
        \end{bmatrix}
        \\
        &= \begin{bmatrix}
            1 & 0 \\
            0 & 1
        \end{bmatrix} = I_2
    \end{align*}
    For all \(\alpha \in \mathbb{R}\)
}
\end{snippet}

\begin{snippet}{linearalgebra-matrix-exponentiation-example-2}
\sexample{Matrix exponentiation example 2}{
    \(\nexists A \suchthat A^2 = B\) where
    \[
        B = \begin{bmatrix}
            0 & 1 \\
            0 & 0
        \end{bmatrix}
    \]
    To prove this, let \(a,b,c,d \in \mathbb{C}\)
    \[
        \begin{bmatrix}
            0 & 1 \\
            0 & 0
        \end{bmatrix}
        =
        {\begin{bmatrix}
            a & b \\
            c & d
        \end{bmatrix}}^2
        =
        \begin{bmatrix}
            a^2+bc & b(a+d) \\
            c(a+d) & bc+d^2
        \end{bmatrix}
    \]
    Since \(c(a+d)=0\), then \(c=0 \land a+d=0\).
    But this contradicts \(b(a+d)=1\) meaning \(a+d \neq 0\).
}
\end{snippet}

\begin{snippet}{linearalgebra-matrix-identity-postmultiplication}
\sproposition{Matrix Identity Postmultiplication}{
    Given a matrix \(A\),
    \[ AI_n=A \]
}
\end{snippet}

\begin{snippet}{linearalgebra-matrix-identity-postmultiplication-proof}
\sproof{Matrix Identity Postmultiplication}{
    Let the matrix \(A\) be defined with the
    elements \(a_{i,j}\).
    Then, by the sifting property % TODO link
    \[
        a_{i,j} = \sum_{k=1}^n
        a_{i,j}\delta_{k,j} = a_{i,j}
    \]
}
\end{snippet}

\begin{snippet}{linearalgebra-matrix-identity-premultiplication}
\sproposition{Matrix Identity Premultiplication}{
    Given a matrix \(A\),
    \[ I_n A=A \]
}
\end{snippet}

\begin{snippet}{linearalgebra-matrix-identity-premultiplication-proof}
\sproof{Matrix Identity Premultiplication}{
    Let the matrix \(A\) be defined with the
    elements \(a_{i,j}\).
    Then, by the sifting property % TODO link
    \[
        a_{i,j} = \sum_{k=1}^n
        \delta_{i,k}a_{k,j} = a_{i,j}
    \]
}
\end{snippet}

\begin{snippet}{linearalgebra-matrix-inverse-definition}
\sdefinition{Matrix Inverse}{
    Let \(M\) be a square matrix of side \(n\).
    A matrix \(B\) is an \textit{inverse}
    of \(M\) if \[BM=MB=I_n\]
    The inverse of \(M\) is denoted by \(M^{-1}\).
}
\end{snippet}

\begin{snippet}{linearalgebra-invertible-matrix-definition}
\sdefinition{Invertible Matrix}{
    A matrix is \textit{invertible} if it has an inverse.
    Otherwise, it is \textit{singular}.
}
\end{snippet}

\begin{snippet}{linearalgebra-uniqueness-of-matrix-inverse}
\sproposition{Uniqueness of matrix inverse}{
    If a matrix \(A\) has an inverse, then it is unique.
}
\end{snippet}

\begin{snippet}{linearalgebra-uniqueness-of-matrix-inverse-proof}
\sproof{Uniqueness of matrix inverse}{
    Suppose a matrix \(A\) has distinct inverses \(B\)
    and \(C\).
    It is possible to show that \(B\) and \(C\) are actually
    the same matrix.
    \[
        C=I_n C = (BA) C = B (AC) = BI_n = B
    \]
}
\end{snippet}

\begin{snippet}{linearalgebra-involution-rule-for-matrix-inverse}
\sproposition{Involution rule for matrix inverse}{
    If \(M\) is an invertible matrix
    \[
        {(M^{-1})}^{-1} = M
    \]
}
\end{snippet}

\begin{snippet}{linearalgebra-involution-rule-for-matrix-inverse-proof}
\sproof{Involution rule for matrix inverse}{
    Since \(M(M^{-1}) = I\), \({(M^{-1})}^{-1}\)
    by uniqueness. % TODO link
}
\end{snippet}

\begin{snippet}{linearalgebra-product-rule-of-inverse-matrices}
\sproposition{Product rule of inverse matrices}{
    For invertible matrices \(A\) and \(B\)
    \[
        {(AB)}^{-1} = A^{-1} B^{-1}
    \]
}
\end{snippet}

\begin{snippet}{linearalgebra-product-rule-of-inverse-matrices-proof}
\sproof{Product rule of inverse matrices}{
    TODO
}
\end{snippet}

\begin{snippet}{linearalgebra-matrix-left-and-write-inverses}
\sdefinition{Matrix left and write inverses}{
    Let \(A\) is an \(m \times n\) matrix. A matrix \(B\)
    is called a \textit{right inverse} of \(A\)
    if \(AB=I_m\).
    A matrix \(B\) is called a \textit{right inverse} of \(A\)
    if \(BA=I_n\).
}
\end{snippet}

\begin{snippet}{linearalgebra-inverse-of-a-non-square-matrix}
\sproposition{Inverse of a non-square matrix}{
    If \(A\) is a non-square matrix, it cannot have
    both a \textit{left inverse} and a \textit{right inverse}.
}
\end{snippet}

\begin{snippet}{linearalgebra-inverse-of-a-square-matrix}
\sproposition{Inverse of a square matrix}{
    If \(A\) is a square matrix
    with a left inverse \(B\),
    then \(B\) is also a right inverse.
}
\end{snippet}

\begin{snippet}{linearalgebra-matrix-invertibility}
\sproposition{Matrix invertibility}{
    A matrix \(M\) is invertible iff
    \(\det(M) \neq 0\).
}
\end{snippet}

\end{document}